{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.sparse\n",
    "from scipy.sparse import hstack\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net imports\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import History \n",
    "from keras.models import load_model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.genfromtxt(\"train_clean.csv\", encoding=\"utf-8\", delimiter=\"\\t\", dtype = str)\n",
    "test = np.genfromtxt(\"test_clean.csv\", encoding=\"utf-8\", delimiter=\"\\t\", dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "X = tf.fit_transform(train[:, 0])\n",
    "y = train[:, 1]\n",
    "test = tf.transform(test)\n",
    "encoder = LabelBinarizer()\n",
    "X_dim1 = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining all the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_model = MultinomialNB(alpha=0.175)\n",
    "svm_model = LinearSVC(C=0.25, loss='squared_hinge', penalty='l2')\n",
    "svm_model = CalibratedClassifierCV(svm_model) #to predict probabilities\n",
    "logit_model = LogisticRegression(C=2.4)\n",
    "tree_model = DecisionTreeClassifier(max_depth=1000)\n",
    "rf_model = RandomForestClassifier\n",
    "\n",
    "models = [mnb_model, svm_model, logit_model, tree_model, rf_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(X, y, model, n):\n",
    "    accuracies = []\n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1/n))\n",
    "        model = model\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "    \n",
    "        count = 0\n",
    "        for j, prediction in enumerate(predictions):\n",
    "            if y_test[j] == prediction:\n",
    "                count += 1\n",
    "        accuracies.append(count / y_test.shape[0])\n",
    "    print(\"Your accuracies are: \" + str(accuracies))\n",
    "    print(\"Your average accuracy is: \" + str(sum(accuracies) / len(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validating each model individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    kfold(X, y, model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_svm = VotingClassifier(estimators=[('mnb', mnb_model), ('svm', svm_model)], voting='soft', n_jobs=6)\n",
    "mnb_svm_logit = VotingClassifier(estimators=[('mnb', mnb_model), ('svm', svm_model), ('logit', logit_model)], voting='soft', n_jobs=6)\n",
    "mnb_logit = VotingClassifier(estimators=[('mnb', mnb_model), ('logit', logit_model)],  voting='soft', n_jobs=6)\n",
    "\n",
    "ensembles = [mnb_svm_classifier, mnb_svm_logit, mnb_logit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ensemble in ensembles:\n",
    "    kfold(X, y, ensemble, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputting predictions on full data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_svm.fit(X, y)\n",
    "mnb_svm_logit.fit(X, y)\n",
    "mnb_logit.fit(X, y)\n",
    "\n",
    "mnb_svm_preds = mnb_svm.predict(test)\n",
    "mnb_svm_logit_preds = mnb_svm_logit.predict(test)\n",
    "mnb_logit_preds = mnb_logit.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtr = csv.writer(open ('mnb_svm_predictions.csv', 'w'), delimiter=',', lineterminator='\\n')\n",
    "for p in mnb_svm_preds : wtr.writerow ([p])\n",
    "\n",
    "wtr = csv.writer(open ('mnb_svm_logit_predictions.csv', 'w'), delimiter=',', lineterminator='\\n')\n",
    "for p in mnb_svm_logit_preds : wtr.writerow ([p])\n",
    "    \n",
    "wtr = csv.writer(open ('mnb_logit_predictions.csv', 'w'), delimiter=',', lineterminator='\\n')\n",
    "for p in mnb_logit_preds : wtr.writerow ([p])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
